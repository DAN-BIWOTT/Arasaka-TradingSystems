# Arasaka-TradingSystems
A record of Model Evolutions.

# Model Tier Breakdown

The tier system is a neural jack-in to gauge and rank the performance of trading models, based on their accuracy, adaptability, and real-world street cred. Each tier reflects how razor-sharp or glitchy the model runs.

## **Tier Descriptions**

### **S-Tier (Legendary Chrome)**
- **Criteria:**
  - Virtually flawless metrics (e.g., MSE < 0.0001, R² > 0.99999).
  - Zero drag on generalization, no overfitting bugs.
  - Consistently obliterates benchmarks, leaving other models in the dust.
- **Application:**
  - Built for megacorps and high-stakes black-market trading gigs.

### **A-Tier (Elite Runner)**
- **Criteria:**
  - Top-tier performance with metrics like MSE ≤ 0.0005, RMSE ≤ 0.02, and R² > 0.9999.
  - Tight sync between training and test data.
  - Deployment-ready but needs occasional system diagnostics.
- **Application:**
  - Perfect for mid- to high-risk heists in the trading grid.
  - A solid baseline for refining better chrome.

### **B-Tier (Street Samurai)**
- **Criteria:**
  - Reliable performance, e.g., MSE between 0.001 and 0.01, R² > 0.99.
  - Slight overfit skirmishes but nothing too critical.
  - Needs more optimization before it’s ready to run with the big dogs.
- **Application:**
  - Ideal for hustling low-key trades and prototyping next-gen rigs.

### **C-Tier (Edge Runner)**
- **Criteria:**
  - Predictive chops are okay but could use a hardware upgrade (e.g., MSE between 0.01 and 0.05, R² > 0.9).
  - Obvious signs of overfitting or underfitting lurking in the shadows.
  - Needs serious tweaking and modding to become viable.
- **Application:**
  - Good for beta testing fresh ideas but not safe for prime time action.

### **D-Tier (Flatline)**
- **Criteria:**
  - Performance is a total wipeout, e.g., MSE > 0.05, R² < 0.9.
  - Can’t handle the noise, chokes on real-world data.
  - Likely miscalibrated or missing crucial upgrades.
- **Application:**
  - Strictly for comparison and scrap pile diagnostics.

## **How Models Are Evaluated**

Models are scoped and ranked using these core metrics:
- **Mean Squared Error (MSE):** Logs the average squared misses between actual and predicted values.
- **Root Mean Squared Error (RMSE):** Tracks the standard deviation of prediction bugs.
- **Mean Absolute Error (MAE):** Reads the average absolute misses.
- **R-Squared (R²):** Measures how much juice the model pulls from the variance.
- **Explained Variance:** Rates how well the model deciphers data chaos.

## **Current Model Status**
- **Models in A-Tier:**
  - 2.1_Ensemble Model (Linear SVR + SFN)_2024.12.01
  - 2.1_Ensemble Model (Linear SVR + SFN)_2025.01.01
- **Models in B-Tier:**
  - Ensemble Model (Linear SVR + SFN)_2024.11.01

### Note:
Models get patched and re-scanned on the regular. Tier ranks may shift as fresh data or bleeding-edge tech rolls in.
